{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/16 19:36:07 WARN Utils: Your hostname, arthurpfonseca resolves to a loopback address: 127.0.1.1; using 192.168.0.19 instead (on interface wlo1)\n",
      "24/01/16 19:36:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/16 19:36:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"apple_compare\").getOrCreate()\n",
    "# sc = SparkContext(appName='mm_exp', conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+------------+------------+------------+------------+------------+-------+\n",
      "|A_id|        Size|      Weight|   Sweetness| Crunchiness|   Juiciness|    Ripeness|     Acidity|Quality|\n",
      "+----+------------+------------+------------+------------+------------+------------+------------+-------+\n",
      "|   0|-3.970048523|-2.512336381| 5.346329613|-1.012008712| 1.844900361| 0.329839797|-0.491590483|   good|\n",
      "|   1|-1.195217191|-2.839256528| 3.664058758| 1.588232309| 0.853285795| 0.867530082|-0.722809367|   good|\n",
      "|   2|-0.292023862|-1.351281995|-1.738429162|-0.342615928| 2.838635512|-0.038033328| 2.621636473|    bad|\n",
      "|   3|-0.657195773|-2.271626609| 1.324873847|-0.097874716| 3.637970491|-3.413761338| 0.790723217|   good|\n",
      "|   4|  1.36421682|-1.296611877|-0.384658206| -0.55300577| 3.030874354|-1.303849429| 0.501984036|   good|\n",
      "|   5|-3.425399755|-1.409082204|-1.913511195|-0.555774864| -3.85307147| 1.914615916|-2.981523169|    bad|\n",
      "|   6| 1.331605736| 1.635955715| 0.875974244| -1.67779794| 3.106344455|-1.847416733| 2.414170509|   good|\n",
      "|   7|-1.995462096| -0.42895848| 1.530643583|-0.742971676| 0.158834003| 0.974437858|-1.470125066|   good|\n",
      "|   8|-3.867632233|-3.734513576| 0.986429067| -1.20765455| 2.292872919| 4.080920787|-4.871904758|    bad|\n",
      "|   9|-0.727982709|-0.442820353|-4.092222827| 0.597512917| 0.393714261| 1.620856772| 2.185607723|    bad|\n",
      "|  10| -2.69933629|-1.329506988|-1.418506853|-0.625545768| 2.371074371| 3.403164523|-2.810808169|    bad|\n",
      "|  11| 2.450959845|-0.564177407|-1.635040727| 0.942399869| -2.08731667| 1.214321691| 1.294323927|   good|\n",
      "|  12|-0.170811719|-1.867271142|-1.771844728| 2.413155317|-3.094554738|-0.624884375|-2.076113997|    bad|\n",
      "|  13|-1.345530536|-1.623701121| 2.044143754| 1.754812932| 0.997567093| 0.434179855| 1.724026084|   good|\n",
      "|  14| 2.839580937|-0.344798192|-1.019797291| 0.894580857|-1.300060883|  0.58237862| 1.709708209|   good|\n",
      "|  15|-2.659887385|-2.795684208| 4.230403587| 0.697550395| 2.180911101|-0.088775396|-1.083620788|   good|\n",
      "|  16|-1.468951547|-1.950359588|-2.214372889| 0.909758509| 2.864448854| 3.965955655|-0.558208683|    bad|\n",
      "|  17|-0.074370177|-4.714749953| 0.249767641| 2.935319065|   1.4097551|-2.643810206| 1.250970347|   good|\n",
      "|  18|-0.302364267| 1.724395847|-2.442337223| 3.465108479| 0.449791675|-0.074362452| 2.493781985|    bad|\n",
      "|  19|-2.108049899| 0.356467403|-1.156193279| 4.326722517| 1.561543116|-4.630174264| -1.37665721|   good|\n",
      "+----+------------+------------+------------+------------+------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df = spark.read.option(\"header\", \"true\").csv(\"apple_quality.csv\")\n",
    "apple_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|        Size|      Weight|\n",
      "+------------+------------+\n",
      "|-3.970048523|-2.512336381|\n",
      "|-1.195217191|-2.839256528|\n",
      "|-0.292023862|-1.351281995|\n",
      "|-0.657195773|-2.271626609|\n",
      "|  1.36421682|-1.296611877|\n",
      "|-3.425399755|-1.409082204|\n",
      "| 1.331605736| 1.635955715|\n",
      "|-1.995462096| -0.42895848|\n",
      "|-3.867632233|-3.734513576|\n",
      "|-0.727982709|-0.442820353|\n",
      "| -2.69933629|-1.329506988|\n",
      "| 2.450959845|-0.564177407|\n",
      "|-0.170811719|-1.867271142|\n",
      "|-1.345530536|-1.623701121|\n",
      "| 2.839580937|-0.344798192|\n",
      "|-2.659887385|-2.795684208|\n",
      "|-1.468951547|-1.950359588|\n",
      "|-0.074370177|-4.714749953|\n",
      "|-0.302364267| 1.724395847|\n",
      "|-2.108049899| 0.356467403|\n",
      "+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df.select([\"Size\", \"Weight\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+------------+------------+------------+------------+------------+-------+\n",
      "|A_id|        Size|      Weight|   Sweetness| Crunchiness|   Juiciness|    Ripeness|     Acidity|Quality|\n",
      "+----+------------+------------+------------+------------+------------+------------+------------+-------+\n",
      "|   0|-3.970048523|-2.512336381| 5.346329613|-1.012008712| 1.844900361| 0.329839797|-0.491590483|   good|\n",
      "|   1|-1.195217191|-2.839256528| 3.664058758| 1.588232309| 0.853285795| 0.867530082|-0.722809367|   good|\n",
      "| 100|-1.581378996|-0.759501459| 0.135359641| 1.881819633| 1.998052361| 0.729362217| 0.286883321|   good|\n",
      "|1000|-1.450722623|-1.873303787|-0.743177804| 1.981552145|-2.092821414| 1.691483862| 0.784607915|    bad|\n",
      "|1001|-0.157271619| 0.829703853| -3.27215596| 1.226894151| -1.36458925| 1.487907926| 1.052510895|    bad|\n",
      "|1003|  0.48573438|-4.694670684| -1.94594246| 2.022091675| 0.861829748|-0.643013894|-1.414626558|   good|\n",
      "|1005|-2.025514845|-1.073743514| -0.56538837|-0.321394847| 0.454941226| 0.248735333| 3.669770294|    bad|\n",
      "|1006|-0.936155999| 0.300120045|-1.943790524| 1.196775043|-1.966993862|-0.662338652|-0.651472669|   good|\n",
      "|1007|-0.533447689|-1.605149271|-5.715134453| 3.093680856| -3.30300905| 2.255091404|-1.981574246|    bad|\n",
      "|1008| 0.617173994|-1.361685937|-2.621162853|-1.075201067| 3.260811348| 1.326728883|-0.805294862|    bad|\n",
      "| 101|-1.111426668|-2.084750358| 2.519879958| 0.918003904| 1.377124216| 0.937208835|-0.894186563|   good|\n",
      "|1010|-3.943657521|-0.792984109| 0.099416637| 1.245084592| 2.432160572| 1.616126875| 4.308434418|    bad|\n",
      "|1011|-0.553438031|-1.485230595| 1.178210805|-0.766074439| 0.726136642| 1.214320842|-3.315902733|   good|\n",
      "|1012|-0.373861901|-0.766067802|-2.417651619|-0.019789441| 0.215198554|-0.588967865| 3.543470082|    bad|\n",
      "|1013| 0.094103112| 0.407294368|-0.390131643| 2.530804324|-3.129980546|-0.322171308|-3.101679757|    bad|\n",
      "|1015| 2.461235858|-1.372053506|-4.432614766| 3.067025691|-0.619639377| 1.440307125| 0.749383473|   good|\n",
      "|1016| 0.209388633| -2.04750402|-1.248701084| 2.054072106|-3.073830134|   0.5649855|-0.909613055|    bad|\n",
      "|1017| 1.387968335|-2.540032008|-2.849653633| 1.081977146| 0.342861974| 1.916185582|  0.62809646|    bad|\n",
      "|1019| 0.546077805| 0.454631306| 2.023503567| 0.251398866|-1.453233643|-1.617008997| 1.220969825|    bad|\n",
      "| 102|-1.921823652|-3.481362426| 0.441475743| 1.777523431|-0.283584197|  0.82291936|-3.504485228|    bad|\n",
      "+----+------------+------------+------------+------------+------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = apple_df.randomSplit(weights=[0.8, 0.2], seed=42)\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthurpfonseca/Documents/Poli/5oQuadriAula/TCC/data-analysis/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/arthurpfonseca/Documents/Poli/5oQuadriAula/TCC/data-analysis/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train_feature_df = train_df.select([\"Size\", \"Weight\", \"Sweetness\", \"Crunchiness\", \"Juiciness\", \"Ripeness\", \"Acidity\"])\n",
    "train_predict_col_df = train_df.select([\"Quality\"])\n",
    "\n",
    "X_train = [list(features) for features in train_feature_df.collect()]\n",
    "y_train = [list(features) for features in train_predict_col_df.collect()]\n",
    "encoder = preprocessing.LabelEncoder().fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthurpfonseca/Documents/Poli/5oQuadriAula/TCC/data-analysis/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_df = test_df.select([\"Size\", \"Weight\", \"Sweetness\", \"Crunchiness\", \"Juiciness\", \"Ripeness\", \"Acidity\"])\n",
    "test_predict_col_df = test_df.select([\"Quality\"])\n",
    "\n",
    "X_test = [list(features) for features in test_feature_df.collect()]\n",
    "y_test = [list(features) for features in test_predict_col_df.collect()]\n",
    "y_test = encoder.transform(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad', 'good', 'bad', 'good', 'good', 'good', 'good', 'good',\n",
       "       'bad', 'good', 'bad', 'good', 'bad', 'good', 'bad', 'good', 'bad',\n",
       "       'bad', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad',\n",
       "       'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'bad',\n",
       "       'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'good', 'bad', 'bad',\n",
       "       'bad', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'bad', 'bad',\n",
       "       'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'bad',\n",
       "       'bad', 'good', 'bad', 'bad', 'good', 'bad', 'bad', 'good', 'bad',\n",
       "       'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'bad',\n",
       "       'good', 'bad', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'good',\n",
       "       'good', 'bad', 'good', 'good', 'good', 'good', 'bad', 'bad',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'bad',\n",
       "       'bad', 'good', 'bad', 'good', 'good', 'bad', 'bad', 'good', 'bad',\n",
       "       'good', 'bad', 'good', 'good', 'good', 'good', 'bad', 'bad', 'bad',\n",
       "       'good', 'good', 'good', 'bad', 'good', 'bad', 'bad', 'bad', 'good',\n",
       "       'good', 'bad', 'good', 'good', 'bad', 'bad', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'bad', 'bad', 'good', 'bad', 'bad', 'bad', 'bad',\n",
       "       'bad', 'bad', 'bad', 'good', 'good', 'bad', 'good', 'good', 'bad',\n",
       "       'bad', 'bad', 'bad', 'good', 'bad', 'bad', 'good', 'good', 'bad',\n",
       "       'bad', 'good', 'bad', 'bad', 'bad', 'bad', 'good', 'good', 'good',\n",
       "       'bad', 'bad', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad',\n",
       "       'bad', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
       "       'good', 'bad', 'good', 'bad', 'bad', 'bad', 'bad', 'good', 'good',\n",
       "       'bad', 'bad', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad',\n",
       "       'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'bad', 'good', 'good', 'good', 'bad', 'bad',\n",
       "       'good', 'bad', 'good', 'bad', 'good', 'bad', 'good', 'good', 'bad',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'good', 'good',\n",
       "       'good', 'bad', 'bad', 'bad', 'good', 'bad', 'good', 'bad', 'good',\n",
       "       'bad', 'good', 'bad', 'good', 'bad', 'bad', 'bad', 'good', 'bad',\n",
       "       'good', 'bad', 'bad', 'good', 'bad', 'bad', 'bad', 'good', 'good',\n",
       "       'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'bad', 'good', 'good', 'bad',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'good',\n",
       "       'good', 'bad', 'good', 'bad', 'bad', 'good', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad', 'bad',\n",
       "       'bad', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'good', 'bad', 'good', 'bad', 'bad', 'bad', 'good',\n",
       "       'bad', 'good', 'good', 'good', 'good', 'bad', 'bad', 'good',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'good', 'good',\n",
       "       'good', 'bad', 'good', 'bad', 'bad', 'good', 'bad', 'bad', 'good',\n",
       "       'good', 'good', 'good', 'good', 'bad', 'bad', 'good', 'bad',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'bad', 'bad',\n",
       "       'good', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'bad',\n",
       "       'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'bad', 'bad',\n",
       "       'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'bad',\n",
       "       'good', 'good', 'bad', 'bad', 'good', 'good', 'bad', 'good', 'bad',\n",
       "       'bad', 'good', 'bad', 'bad', 'bad', 'bad', 'good', 'good', 'good',\n",
       "       'bad', 'good', 'bad', 'good', 'good', 'good', 'bad', 'bad', 'bad',\n",
       "       'good', 'good', 'bad', 'good', 'bad', 'bad', 'bad', 'good', 'good',\n",
       "       'good', 'bad', 'bad', 'good', 'bad', 'good', 'bad', 'bad', 'good',\n",
       "       'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'bad', 'good', 'bad', 'bad',\n",
       "       'bad', 'bad', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good',\n",
       "       'good', 'good', 'good', 'bad', 'bad', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'good',\n",
       "       'bad', 'bad', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good',\n",
       "       'good', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
       "       'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good',\n",
       "       'bad', 'good', 'bad', 'good', 'bad', 'good', 'good', 'bad', 'good',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'bad', 'good',\n",
       "       'bad', 'good', 'bad', 'bad', 'good', 'good', 'good', 'good',\n",
       "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good',\n",
       "       'bad', 'good', 'bad', 'good', 'good', 'good', 'bad', 'good',\n",
       "       'good', 'bad', 'good', 'bad', 'good', 'good', 'good', 'bad',\n",
       "       'good', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'bad',\n",
       "       'good', 'bad', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad',\n",
       "       'bad', 'good', 'bad', 'good', 'bad', 'good', 'bad', 'bad', 'bad',\n",
       "       'good', 'bad', 'good', 'good', 'good', 'bad', 'bad', 'good', 'bad',\n",
       "       'bad', 'bad', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'good',\n",
       "       'bad', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
       "       'good', 'good', 'bad', 'bad', 'good', 'good', 'bad', 'good', 'bad',\n",
       "       'bad', 'bad', 'good', 'bad', 'bad', 'bad', 'bad', 'good', 'good',\n",
       "       'good', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'good',\n",
       "       'good', 'bad', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'good',\n",
       "       'good', 'bad', 'bad', 'bad', 'good', 'bad', 'good', 'good', 'bad',\n",
       "       'good', 'bad', 'bad', 'good', 'good', 'bad', 'good', 'bad', 'good',\n",
       "       'good', 'bad', 'good', 'bad', 'bad', 'bad', 'good', 'bad', 'bad',\n",
       "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good',\n",
       "       'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad', 'bad', 'bad',\n",
       "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good',\n",
       "       'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'good', 'bad',\n",
       "       'bad', 'good', 'good', 'good', 'good', 'bad', 'good', 'bad',\n",
       "       'good', 'good', 'bad', 'bad', 'good', 'bad', 'bad', 'good', 'good',\n",
       "       'bad', 'good', 'good', 'bad'], dtype='<U4')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "encoder.inverse_transform(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8787061994609164\n"
     ]
    }
   ],
   "source": [
    "n_test_samples = len(y_test)\n",
    "n_correct_predicts = 0\n",
    "for i in range(n_test_samples):\n",
    "\tif y_predict[i] == y_test[i]:\n",
    "\t\tn_correct_predicts += 1\n",
    "\n",
    "print(\"accuracy: \", (n_correct_predicts / n_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/arthurpfonseca/Documents/Poli/5oQuadriAula/TCC/data-analysis/.venv/lib/python3.12/site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/arthurpfonseca/Documents/Poli/5oQuadriAula/TCC/data-analysis/.venv/lib/python3.12/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/arthurpfonseca/Documents/Poli/5oQuadriAula/TCC/data-analysis/.venv/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Using cached scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.2 threadpoolctl-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabeledPoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseVector\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mLabeledPoint\u001b[49m(\u001b[38;5;241m0.0\u001b[39m, [\u001b[38;5;241m0.0\u001b[39m]),\n\u001b[1;32m      4\u001b[0m     LabeledPoint(\u001b[38;5;241m1.0\u001b[39m, [\u001b[38;5;241m1.0\u001b[39m]),\n\u001b[1;32m      5\u001b[0m     LabeledPoint(\u001b[38;5;241m1.0\u001b[39m, [\u001b[38;5;241m2.0\u001b[39m]),\n\u001b[1;32m      6\u001b[0m     LabeledPoint(\u001b[38;5;241m1.0\u001b[39m, [\u001b[38;5;241m3.0\u001b[39m])\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      8\u001b[0m svm \u001b[38;5;241m=\u001b[39m SVMWithSGD\u001b[38;5;241m.\u001b[39mtrain(sc\u001b[38;5;241m.\u001b[39mparallelize(data), iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      9\u001b[0m svm\u001b[38;5;241m.\u001b[39mpredict([\u001b[38;5;241m1.0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LabeledPoint' is not defined"
     ]
    }
   ],
   "source": [
    "# from pyspark.mllib.linalg import SparseVector\n",
    "# from pyspark.mllib.classification import SVMWithSGD\n",
    "\n",
    "# # data = [\n",
    "# #     LabeledPoint(0.0, [0.0]),\n",
    "# #     LabeledPoint(1.0, [1.0]),\n",
    "# #     LabeledPoint(1.0, [2.0]),\n",
    "# #     LabeledPoint(1.0, [3.0])\n",
    "# # ]\n",
    "\n",
    "# data = [\n",
    "#     (0.0, 0.0),\n",
    "#     (1.0, 1.0),\n",
    "#     (1.0, 2.0),\n",
    "#     (1.0, 3.0)\n",
    "# ]\n",
    "# svm = SVMWithSGD.train(sc.parallelize(data), iterations=10)\n",
    "# svm.predict([1.0])\n",
    "\n",
    "# svm.predict(sc.parallelize([[1.0]])).collect()\n",
    "\n",
    "# svm.clearThreshold()\n",
    "# svm.predict(numpy.array([1.0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
